[toc]

### 说明

​		附件代码是基于论文所描述的方案所实现，三个文件夹包括MATLAB处理程序，Android系统发声app，Android系统接收app。

### 相关运行环境与开发平台

* 硬件条件
	* 发声app运行设备: Vivo Y93s
	* 接收app运行设备:HuaWei Mate20
* 系统平台
	* 发声app，接收app: Android系统
	* MATLAB处理程序：Windows + MATLAB
* 开发工具
	* 手机应用开发平台
		* Android Studio,版本号:2.3.3
		* JRE: 1.8.0\_112
		* JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o	
		* 其余配置见对应的gradle文件
	* MATLAB版本: 9.4.0.813654 (R2018a)
	
### 系统设计

#### 运行流程

​		使用一个智能设备( Vivo Y93s)运行发声app发出指定音频。

##### 1.离线模型

​		使用另一个智能设备(HuaWei Mate20)运行接收app，在主界面录音并生成录音数据的wav文件即可，后续使用MATLAB进行计算。

##### 2.在线模型

​		使用另一个智能设备(HuaWei Mate20)运行接收app，进入compass界面后即可运行使用。

#### 多模块设计

​		多模块设计针对于Android系统下接收app设定。

​		在系统运行中，各个模块功能的并行运行是突出的。因此对于接收app，系统涵盖的模块可以分为:传感器数据监听模块，录音模块，数据处理模块，显示模块等。
​			
​		传感器数据监听模块:现在的Android系统开发已经非常完善，在传感器方面，开发者也提高了用户方便的接口。在Android系统下，用户可创建一个SensorManager对象对实例化的传感器实时监听和数据读取。在设备中注册了陀螺仪，加速计和磁力传感器三个传感器，并且实时监听器数据。系统运行时，从SensorEvent对象中读取传感器数据，在重写onSensorChanged方法中，根据数据进行相应的处理。
​			
​		录音模块:需要补充说明的是，Android 6.0以后。为了保护用户的隐私，开发者将一些应用权限不能随意获取，而是放在了应用运行的时候才去申请，同样对麦克风权限的申请也是需要动态申请的。当获取麦克风权限后进行录音，该模块会将捕获的音频信号进行声道的分离，转换并存储的数据会用于后续的信号处理和时延计算。
​			
​		数据处理模块:对于存储的音频数据，该模块主要用于对录音数据进行到达时间差的计算，并且反馈指引所需的角度和状态判别。通过对指定长度的录音数据进行截取，先后经过滤波处理等清洗操作，最后调用自定义的Correlation进行计算。在滤波操作中需要借助dsp-collection这一个jar包的帮助。最后计算的结果会传入到显示模块。
​			
​		显示模块:显示模块通过传入的结果进行方向的绘制，主要依赖于graphics库进行界面的绘制。该模块的显示界面包括了方向指示，同时也会和地理方向相结合，方便用户寻找方向，相关的数据会反馈在界面上。
​			
​		对于发声的设备，主要就是通过捕获用户的输入，从而产生相应的声波，由于实现难度并不是很大，所以不做过多的介绍。在前面所描述的系统核心和数据处理流程简图如下图所示。

<img src="C:\Users\ASUS\Desktop\Project-master\figure\dataflow.png" width = "50%" height = "50%"  align=center />

#### 运行方式与界面

##### 1.发声app

​		通过选择波形和对应的频率数据，点击PLAY键将可以单声道播放对应的音频,点击PAUSE即可暂停播放。

<img src="C:\Users\ASUS\Desktop\Project-master\figure\voice.jpg" width = "40%" height = "40%"  align=center />

##### 2.接收app

​		在下图所示通过选择录音，并且选择是否产生wav文件进行录音，期间可以绘制前一秒中部分的数据波形，在此界面下通过选择“产生wav文件"生成相对应的录音文件并保存在手机存储中，通过多个位置的操作，从而可以获得一系列的wav文件，这些文件将应用于后期的离线计算。

<img src="C:\Users\ASUS\Desktop\Project-master\figure\collect.jpg" width = "40%" height = "40%"  align=center />

​		在在线指引的模型下，如下图所示系统会默认打开麦克风并开始采集数据，当手机状态“静止时”才会收集有效数据，当产生一定量的有效数据后，系统后台将会计算出目前声源相对应手机中心的方向，也就是图中的青绿色线，并且显示与手机y轴的夹角与当前的方向(如图中“西”所示)，轮盘指引的方向则是对应的地理方向，从而方便我们寻迹。

<img src="C:\Users\ASUS\Desktop\Project-master\figure\compass.jpg" width = "40%" height = "40%"  align=center />

##### 3.MATLAB

将采集到的wav文件通过Tdoa.m逐个分析求解，最后通过Chan3Model.m文件进行汇总计算

#### 文件结构部分说明

##### MATLAB-offline

<img src="C:\Users\ASUS\Desktop\Project-master\figure\structure1.png" width = "50%" height = "50%"  align=center />

其余两个文件中含有Android系统固定的许多文件，因此只对部分说明。

##### GetSoundtest

<img src="C:\Users\ASUS\Desktop\Project-master\figure\structure2.png" width = "50%" height = "50%"  align=center />

##### Voice

这一部分实现较为简单，因此不做赘述。

### 补充说明

* 1.温度等参数需要根据环境适当修改
* 2.麦克风所在直线与手机y轴不共线时，可以适当补偿角度